from sentence_transformers import SentenceTransformer
from pinecone import Pinecone, ServerlessSpec
from tqdm import tqdm
import json
from  Retrieval import    RetrievalService
from  expansion_service import ExpansionService
from ollama_interface import OllamaInterface
import pandas as pd
import os


def load_data_from_json(file_path):
    """
    Load data from a JSON file.

    :param file_path: Path to the JSON file.
    :return: Data loaded from the JSON file.
    """
    with open(file_path, 'r') as file:
        data = json.load(file)
    return data

def create_rag_prompt(question, retrieved_context, k=3):
    """
    Create a RAG prompt dynamically using the top-k retrieved passages.

    :param question: The question to be answered.
    :param retrieved_context: A list of tuples where each tuple contains a passage and its relevance score.
    :param k: Number of passages to include in the prompt.
    :return: A formatted string containing the RAG prompt.
    """
    passages = "\n".join([f"passage {i + 1}: {retrieved_context[i][0]}" for i in range(min(k, len(retrieved_context)))])
    
    return f"""
            <|begin_of_text|><|start_header_id|>system<|end_header_id|>

            Answer the question based on the given passages below. Keep the answer concise.
            <|eot_id|><|start_header_id|>user<|end_header_id|>

            ## Passages:
            {passages}

            ## Question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>

            ##Answer:
            """


def get_queries(path):
    df = pd.read_parquet(path)
    questions = df['question'].tolist()
    return questions

def get_real_answer_list(path):
    df = pd.read_parquet(path)
    # Extract the inner list from the single list wrapper
    answer_list = df['short_answers'].iloc[0]
    return answer_list


def calculate_threshold(initial_retrieval):
        first_value = initial_retrieval[0][1]
        last_value = initial_retrieval[-1][1]
        # Calculate the difference
        interval_threshold = first_value - last_value
        return interval_threshold
    

def is_real_answer_included(real_answers: list[str], llm_response: str) -> bool:
    """
    Evaluates whether any of the real answers is included in the LLM response.

    Args:
        real_answers (list[str]): The ground truth answers from NQ.
        llm_response (str): The response generated by the LLM.

    Returns:
        bool: True if any real answer is included in the LLM response, False otherwise.
    """
    if not real_answers or not llm_response:
        return False

    # Normalize LLM response
    llm_response = llm_response.strip().lower()

    # Check if any real answer is included
    for real_answer in real_answers:
        if real_answer.strip().lower() in llm_response:
            return True

    return False




model = SentenceTransformer('intfloat/e5-base-v2')

# Initialize Pinecone
pinecone_index_name="dynamic"
pinecone_api_key="pcsk_5SLo1E_SPpKBieD8wQRuRf9G7xfYrVWDLWUAkfRC3X5xjMpDhy7j8CH3SEen8kJiNbMjav"
data_path="/home/student/dynamic-rechunking-RAG/data/passage_to_location.json"
retrieval_service = RetrievalService(pinecone_index_name=pinecone_index_name, pinecone_api_key=pinecone_api_key)
expansion_service = ExpansionService()
ollama_service=OllamaInterface()
data=retrieval_service.load_data(data_path)
retrieval_service.index_and_upsert_documents(data, to_index_flag=True, to_upsert_flag=True, batch_size=64)
queries=get_queries("/home/student/dynamic-rechunking-RAG/data/first_5000_rows.parquet")
real_answers = get_real_answer_list('/home/student/dynamic-rechunking-RAG/data/first_5000_rows.parquet') 
n_neighbors_list = [1, 2, 5, 10, 20, 40, 60]

hyperparams_status_file = "/home/student/dynamic-rechunking-RAG/data/hyperparams_status.json"
accuracy_file = "/home/student/dynamic-rechunking-RAG/data/hyperparams_accuracy.json"

if os.path.exists(hyperparams_status_file):
    with open(hyperparams_status_file, "r") as f:
        remaining_hyperparams = json.load(f)
else:
    remaining_hyperparams = {"n_neighbors": n_neighbors_list}
    
if os.path.exists(accuracy_file):
    with open(accuracy_file, "r") as f:
        accuracy_data = json.load(f)
else:
    accuracy_data = {}

for n_neighbors in tqdm(remaining_hyperparams["n_neighbors"], desc="n_neighbors Progress"):
    correct_answers = 0
    total_queries = len(queries)
    results = []  # To store all data for the current `n_neighbors`


    for i, query in tqdm(enumerate(queries), desc=f"Processing queries for n_neighbors={n_neighbors}"):
        distilled_passages = []
        initial_retrieval = retrieval_service.search_dense(query, top_k=20)
        interval_threshold = calculate_threshold(initial_retrieval)

        for initial_passage in initial_retrieval:
            expanded_passage = expansion_service.expand_passages(
                initial_passage[0], n_neighbors=n_neighbors
            )
            distilled_passage = expansion_service.query_focused_rechunk(
                query, expanded_passage, float(initial_passage[1]) - interval_threshold
            )
            distilled_passages.append(distilled_passage)

        rerenaked_passages = expansion_service.rerank_chunks(query, distilled_passages)
        rag_prompt = create_rag_prompt(query, rerenaked_passages)
        response = ollama_service.send_message(rag_prompt)
        
        # Extract real answer and check correctness using the provided method
        real_answer_list = real_answers[i]
        is_correct = is_real_answer_included(real_answer_list, response)
        if is_correct:
            correct_answers += 1
            
                # Save query-specific data
        results.append({
            "query": query,
            "llm_response": response,
            "real_answers": real_answer_list,
            "is_correct": is_correct
        })

    # Compute accuracy for current n_neighbors
    accuracy = correct_answers / total_queries if total_queries > 0 else 0.0
    accuracy_data[n_neighbors] = accuracy

        # Save results for current n_neighbors
    result_file = f"/home/student/dynamic-rechunking-RAG/data/results_n_neighbors_{n_neighbors}.json"
    with open(result_file, "w") as json_file:
        json.dump(results, json_file, indent=4)
    
    # Save progress
    with open(accuracy_file, "w") as json_file:
        json.dump(accuracy_data, json_file, indent=4)

    remaining_hyperparams["n_neighbors"].remove(n_neighbors)
    with open(hyperparams_status_file, "w") as f:
        json.dump(remaining_hyperparams, f, indent=4)

    












   






